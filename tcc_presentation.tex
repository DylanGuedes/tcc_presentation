\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}

\usetheme{JuanLesPins}

\title{TCC 1}
\subtitle{PROCESSAMENTO DE DADOS EM UMA PLATAFORMA DE CIDADES INTELIGENTES}
\author{Dylan Guedes}
\institute{UnB Gama}
\date{\today}

\begin{document}
  \input{slides/1}
  \input{slides/2}
  \input{slides/3}
  \input{slides/4}
  \input{slides/5}
  \input{slides/6}
  \input{slides/7}
  \input{slides/8}
  \input{slides/9}
  \input{slides/10}
  \input{slides/11}

  \begin{frame}
      \frametitle{Arquitetura Kappa}
      \begin{itemize}
          \item Utiliza somente processamento \textit{streaming}.
          \item Utiliza a retenção do log para uso de dados históricos.
          \item Baixa latência.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Análise de Ferramentas}
      \begin{itemize}
          \item Análise de ferramentas de processamento streaming e batch.
          \item Análise de broker.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Processamento batch - MapReduce vs Spark}
      \begin{itemize}
          \item MapReduce tem latência bem maior que o Spark.
          \item Spark apresenta biblioteca de ML.
          \item Spark pode ser usado como processamento streaming.
          \item Hadoop permite uso de qualquer linguagem que possua interação
              com i/o do SO.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Processamento streaming - Spark vs Storm}
      \begin{itemize}
          \item Storm apresenta menor latência que o Spark.
          \item Abordagens diferentes - Spark usa micro-batch, Storm utiliza
              streaming.
          \item Spark pode ser usado para processamento batch.
          \item Spark dispõe de biblioteca de ML.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Broker - Kafka vs RabbitMQ}
      \begin{itemize}
          \item RabbitMQ já é utilizado pelo InterSCity.
          \item Kafka apresenta performance superior.
          \item Kafka tem integração nativa com o Spark.
          \item RabbitMQ dispõe de plugins para extender as funcionalidades.
          \item RabbitMQ permite a utilização de filas e tópicos mais complexos.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Novo serviço de processamento}
      \begin{itemize}
          \item<2-> Utilização da \textbf{Arquitetura Kappa}.
          \item<3-> \textbf{Apache Spark} para processamento \textit{streaming};
          \item<4-> \textbf{Apache Kafka} como \textit{broker}.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Arquitetura Kappa}
      \begin{itemize}
          \item Complexidade da Arquitetura Lambda;
          \item Melhor adoção para o time do InterSCity.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Apache Spark}
      \begin{itemize}
          \item Biblioteca de ML nativa;
          \item Poder utilizar Python;
          \item Fácil troca para a Arquitetura Lambda.
              \begin{figure}
                  \includegraphics[scale=0.3]{figures/spark_logo.png}
              \end{figure}
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Apache Kafka}
      \begin{itemize}
          \item Ajuda na implementação da Arquitetura Kappa;
          \item Produtor nativo para o Spark Streaming;
          \item Utilização somente no processamento de dados.
              \begin{figure}
                  \includegraphics[scale=0.3]{figures/kafka_logo.png}
              \end{figure}
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Implementação}
      \begin{itemize}
          \item Divisão em três etapas:
              \begin{itemize}
                  \item Configuração do ambiente;
                  \item Interoperabilidade entre os serviços;
                  \item Possibilidade de extender o processamento de uma forma customizável.
              \end{itemize}
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Shock}
      \begin{itemize}
          \item Aplicação que abstrai o uso do Spark e do Kafka;
          \item Faz parte do novo serviço de processamento de dados;
          \item Carrega novas operações para o pipeline de dados via Kafka;
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Ciclo básico do Shock}
          \begin{figure}
              \includegraphics[scale=0.3]{figures/shock.png}
          \end{figure}
  \end{frame}

  \begin{frame}
      \frametitle{Contribuições}
      \begin{itemize}
          \item Novo serviço de processamento
          \item Aplicação que abstrai outras ferramentas, e que é extensível
          \item Possibilidade de uso de algoritmos sofisticados
          \item Possibilidade de atuação em cenários mais extremos
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Próximos passos - TCC 2}
      \begin{itemize}
          \item Segunda rodada de revisão na bibliografia.
          \item Desacoplar o núcleo do Shock do Kafka.
          \item Testar o núcleo do Shock.
          \item Documentar a API de serviços.
          \item Disponibilizar customização de janelas de micro-batch.
          \item Utilizar recuperação de dados históricos através dos logs do Kafka.
      \end{itemize}
  \end{frame}

  \begin{frame}
      \frametitle{Próximos passos - Após o TCC 2}
      \begin{itemize}
          \item Utilizar outras estruturas de dados (não só RDD's).
          \item Uso de check-points.
          \item Múltiplos streams.
      \end{itemize}
  \end{frame}
\end{document}
